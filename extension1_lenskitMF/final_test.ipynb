{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exact-locking",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-sunglasses",
   "metadata": {},
   "source": [
    "## Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "backed-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "from lenskit.batch import MultiEval, predict, recommend\n",
    "from lenskit.crossfold import partition_users, SampleN\n",
    "from lenskit.algorithms import basic, als, svd, bias\n",
    "from lenskit import topn, util, Recommender, batch\n",
    "from lenskit.topn import precision, ndcg, recall\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import binpickle\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "literary-navigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39605</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39605' processes=1 threads=1, memory=17.18 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set LOCAL to True for single-machine execution while developing\n",
    "# Set LOCAL to False for cluster execution\n",
    "LOCAL = True\n",
    "\n",
    "if LOCAL:\n",
    "    # This line creates a single-machine dask client\n",
    "    client = Client()\n",
    "else:    \n",
    "    # This line creates a SLURM cluster dask and dask client\n",
    "    # Logging outputs will be stored in /scratch/{your-netid}\n",
    "    \n",
    "    cluster = SLURMCluster(memory='4GB', cores=2, python='/scratch/work/public/dask/bin/python', \n",
    "                               local_directory='/tmp/{}/'.format(os.environ['SLURM_JOB_USER']),\n",
    "                               job_extra=['--output=/scratch/{}/slurm-%j.out'.format(os.environ['SLURM_JOB_USER'])])\n",
    "\n",
    "    cluster.submit_command = 'slurm'\n",
    "    cluster.scale(100)\n",
    "\n",
    "    display(cluster)\n",
    "    client = Client(cluster)\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-signature",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "strategic-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 100 subtrain version for tuning\n",
    "train_dir = '/scratch/zh2095/quarantini/cf_train.parquet'\n",
    "test_dir = '/scratch/zh2095/quarantini/cf_test.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "combined-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 22.115638 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_train = pd.read_parquet(train_dir)\n",
    "df_test = pd.read_parquet(test_dir)\n",
    "\n",
    "print('took %f s'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recovered-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns = {'user_id':'user', 'track_id':'item', 'count':'rating'}, inplace = True)\n",
    "df_test.rename(columns = {'user_id':'user', 'track_id':'item', 'count':'rating'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-chain",
   "metadata": {},
   "source": [
    "## Run the tuned model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cooperative-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best configuration\n",
    "best_features = 100\n",
    "best_reg = 1\n",
    "best_weight = 10\n",
    "iterations = 20\n",
    "use_ratings = True\n",
    "\n",
    "data = (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "multiple-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing deprecated MultiEval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d300d8d2f34f54a2d2f4bff0f048a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ImplicitMF:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 6607.842613 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "eval = MultiEval('result_test', recommend=500, save_models=False)  #set save_models=True when running on the full dataset\n",
    "eval.add_datasets(data, name='Song')   \n",
    "best_mdl = [als.ImplicitMF(features=best_features, iterations=iterations, reg=best_reg, \n",
    "                           use_ratings = use_ratings, weight=best_weight, method='cg', progress=tqdm)]\n",
    "eval.add_algorithms(best_mdl, attrs=['features'], name='ImplicitMF')\n",
    "eval.run(progress = tqdm)\n",
    "\n",
    "print('took %f s'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-processing",
   "metadata": {},
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approximate-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_test = pd.read_parquet('result_test/recommendations.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "independent-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "# rla.add_metric(topn.ndcg)\n",
    "# rla.add_metric(topn.recall)\n",
    "rla.add_metric(precision, k=500)\n",
    "rla.add_metric(ndcg, k=500)\n",
    "rla.add_metric(recall, k=500)\n",
    "\n",
    "raw_metrics_test = rla.compute(recs_test, df_test, include_missing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "novel-politics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.012088\n",
       "ndcg         0.209590\n",
       "recall       0.450778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test = raw_metrics_test.drop(columns=['nrecs']).fillna(0).mean()\n",
    "metrics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-leader",
   "metadata": {},
   "source": [
    "## Calculate MAP manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baking-maria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@500 = 0.028605261753119414\n",
      "took 2662.503888 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "AP = []\n",
    "for k in range(1,501):\n",
    "    rla_map = topn.RecListAnalysis()\n",
    "    rla_map.add_metric(precision, k=k)\n",
    "    raw_metrics_map = rla_map.compute(recs_test, df_test, include_missing=False)\n",
    "    metrics_map = raw_metrics_map.drop(columns=['nrecs']).fillna(0).mean()\n",
    "    AP.append(metrics_map[0])\n",
    "\n",
    "MAP = np.mean(AP)\n",
    "print(f'MAP@{k} = {MAP}')\n",
    "print('took %f s'%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-conditioning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
